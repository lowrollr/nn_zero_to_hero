{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we load the words dataset and create char to id and id to char mappings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open('../l2_makemore/names.txt').read().splitlines()\n",
    "chars = ['.'] + sorted(list(set(''.join(words))))\n",
    "stoi = {c:i for i,c in enumerate(chars)}\n",
    "itos = {i:c for i,c in enumerate(chars)}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this model we will consider the 3 previous characters to predict the next character in a name. As we did in the previous lecture, we can use the '.' character to denote start and end of sequence.\n",
    "\n",
    "We can print a few examples to see that it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... -----> e\n",
      "..e -----> m\n",
      ".em -----> m\n",
      "emm -----> a\n",
      "mma -----> .\n",
      "... -----> o\n",
      "..o -----> l\n",
      ".ol -----> i\n",
      "oli -----> v\n",
      "liv -----> i\n",
      "ivi -----> a\n",
      "via -----> .\n",
      "... -----> a\n",
      "..a -----> v\n",
      ".av -----> a\n",
      "ava -----> .\n",
      "... -----> i\n",
      "..i -----> s\n",
      ".is -----> a\n",
      "isa -----> b\n",
      "sab -----> e\n",
      "abe -----> l\n",
      "bel -----> l\n",
      "ell -----> a\n",
      "lla -----> .\n",
      "... -----> s\n",
      "..s -----> o\n",
      ".so -----> p\n",
      "sop -----> h\n",
      "oph -----> i\n",
      "phi -----> a\n",
      "hia -----> .\n"
     ]
    }
   ],
   "source": [
    "block_size = 3\n",
    "\n",
    "X, Y = [], []\n",
    "\n",
    "for w in words[:5]:\n",
    "    context = [0] * block_size\n",
    "    for c in w + '.':\n",
    "        ix = stoi[c]\n",
    "        X.append(context)\n",
    "        Y.append(ix)\n",
    "        print(''.join(itos[i] for i in context), '----->', itos[ix])\n",
    "        context = context[1:] + [ix]\n",
    "\n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's create the embedding vectors. We can first experiment with a smaller size -- I chose 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 3])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = torch.randn((27, 3), requires_grad=True)\n",
    "emb = C[X]\n",
    "emb.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hidden layer will connect the embeddings to a linear layer, we choose a size of 100 neurons. \n",
    "\n",
    "The input size will be the block_size (3) multiplied by the embedding size (also 3) = 9:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = torch.randn((9, 100), requires_grad=True)\n",
    "b1 = torch.randn(100, requires_grad=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to feed the embeddings into the hidden layer, we will need to squash the dimensions such that they are of the shape (X, 9) instead of (X, 3, 3) which we can accomplish with the *view* method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-4.0524, -2.8991, -0.4801,  ..., -3.7221,  5.8062, -4.7162],\n",
       "        [-3.2314, -4.0210,  1.8129,  ..., -2.9598,  3.2823, -5.3950],\n",
       "        [ 0.3004,  3.0419,  0.9281,  ...,  3.4617,  7.6725, -3.5616],\n",
       "        ...,\n",
       "        [-1.5714, -2.8640,  4.8486,  ...,  3.9265,  5.8829,  3.0628],\n",
       "        [ 2.0637,  2.6813, -1.5872,  ...,  8.1014,  3.7056, -2.3246],\n",
       "        [-5.3088, -1.4802, -3.5599,  ..., -6.9162, -0.5940, -9.6791]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(emb.view(-1, 9) @ W1) + b1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the output layer will map the 100 activations from the hidden layer to 27 activations that we will use to represent the probability distribution for each of the 27 possible characters.\n",
    "\n",
    "In total, the parameters in our network include:\n",
    " * embedding weights (C)\n",
    " * hidden layer weights (W1)\n",
    " * hidden layer biases (b1)\n",
    " * output layer weights (W2)\n",
    " * output layer biases (b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2 = torch.randn((100, 27), requires_grad=True)\n",
    "b2 = torch.randn(27, requires_grad=True)\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can write a forward propogation function to propogate data through the network. Note that we do not apply an activation to the output layer yet (because we are going to use Cross Entropy Loss! which assumes the values are still logits)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(x, parameters):\n",
    "    C, W1, b1, W2, b2 = parameters\n",
    "    emb = C[x]\n",
    "    h = (emb.view(-1, emb.shape[1] * emb.shape[2]) @ W1) + b1\n",
    "    h = h.tanh()\n",
    "    h = (h @ W2) + b2\n",
    "    return h # returns logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]), torch.Size([32, 3]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward(X, parameters).shape, X.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can write a function the performs one step of optimization. It feeds some input through the network, computes the cross entropy loss on the output logits, then performs a gradient descent step on all the paramter weights and resets the gradients to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_step(x, y, parameters, lr=0.1):\n",
    "    logits = forward(x, parameters)\n",
    "    loss = torch.nn.functional.cross_entropy(logits, y)\n",
    "    loss.backward()\n",
    "    for p in parameters:\n",
    "        p.data -= p.grad * lr\n",
    "        p.grad = None\n",
    "    return loss.item()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that running 2 optimization steps decreases the loss!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.095874786376953"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimize_step(X, Y, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.901688575744629"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimize_step(X, Y, parameters)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another useful function would be a way to instantiate a network with different layer hyperparamters so that we can easily experiment with different configurations. We can wrap the instantiation of each of the layers in *init_parameters*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_parameters(num_chars, block_size, embedding_size, hidden_layer_size):\n",
    "    C = torch.randn((num_chars, embedding_size), requires_grad=True)\n",
    "    W1 = torch.randn((embedding_size * block_size, hidden_layer_size), requires_grad=True)\n",
    "    b1 = torch.randn(hidden_layer_size, requires_grad=True)\n",
    "    W2 = torch.randn((hidden_layer_size, num_chars), requires_grad=True)\n",
    "    b2 = torch.randn(num_chars, requires_grad=True)\n",
    "\n",
    "    return [C, W1, b1, W2, b2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = init_parameters(27, 3, 3, 100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might want to mess around with changing the block size, so we can create a function that creates input data with a given block size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_inputs_and_labels(words, block_size):\n",
    "    X, Y = [], []\n",
    "\n",
    "    for w in words:\n",
    "        context = [0] * block_size\n",
    "        for c in w + '.':\n",
    "            ix = stoi[c]\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "            context = context[1:] + [ix]\n",
    "\n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    return X, Y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, now that we are using a much larger number of paramters, we need to make sure that we don't accidentally overfit to the data we train on. To combat this, we will split the data into a training set, a validation set, and a test set wtih this function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dev_test_split(words, train_size=0.8, dev_size=0.1):\n",
    "    random.shuffle(words)\n",
    "    assert train_size + dev_size < 1\n",
    "    num_words = len(words)\n",
    "    train_split = int(num_words * train_size)\n",
    "    dev_split = int(num_words * (train_size + dev_size))\n",
    "    train_words = words[:train_split]\n",
    "    dev_words = words[train_split:dev_split]\n",
    "    test_words = words[dev_split:]\n",
    "    return train_words, dev_words, test_words"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can split the data and create input tensors for each of the datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_words, dev_words, test_words = train_dev_test_split(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = build_inputs_and_labels(train_words, block_size)\n",
    "X_dev, Y_dev = build_inputs_and_labels(dev_words, block_size)\n",
    "X_test, Y_test = build_inputs_and_labels(test_words, block_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting it all together, we can write a gradient descent algorithm. The features include:\n",
    "* Minibatches: It's very slow to perform a gradient descent step on the entire dataset. Instead, we can samples a subset of the data and perform a gradient descent step on the sample, which should allow us to converge more quickly.\n",
    "* lr_deacy: Modern optimizers use all sorts of techniques to fine-tune the learning rate during training. For our purposes, we can just apply a decay factor over time s.t. (new lr) = (1 - decay_rate) * old_lr\n",
    "* Regularization: We can also include a regularization term in the loss function, which will normalize the model's output (by punishing large weights) and help prevent against overfitting. My implementation is very janky but does the job.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(x, y, parameters, iterations=100, minibatch_size=100, lr=0.1, lr_decay=0.001, regularization=0.01, print_every=10):\n",
    "    losses = []\n",
    "    for i in range(iterations):\n",
    "        batch_indices = torch.randint(0, x.shape[0], (minibatch_size,))\n",
    "        xi = x[batch_indices]\n",
    "        yi = y[batch_indices]\n",
    "        reg_term = torch.sum(torch.stack([(p**2).sum() for p in parameters])).divide(torch.sum(torch.tensor([p.numel() for p in parameters]))) * regularization\n",
    "        loss = optimize_step(xi, yi, parameters, lr) + reg_term\n",
    "        losses.append(loss)\n",
    "        if i % print_every == 0:\n",
    "            print(f'Iteration {i} loss: {loss}')\n",
    "        lr = lr * (1 - lr_decay)\n",
    "    return losses\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the topic of learning rate decay, we can play around with a learning rate and a decay rate to see how the learning rate changes over time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11a582910>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "timesteps=300000\n",
    "init_lr = 0.2\n",
    "decay_rate = 0.00002\n",
    "plt.plot(np.arange(timesteps), [init_lr * ((1 - decay_rate) ** i)for i in range(1, timesteps + 1)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E01: \n",
    "#### *Tune the hyperparameters of the training to beat my best validation loss of 2.2*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running many different experiments, I was able to improve upon the results in lecture by increasing the minibatch size, and using learning rate decay to gradually reduce the learning rate over the course of training. I think that using a larger minibatch size resulted in smoother convergence than the size 32 batches we used in lecture, which helped us reach a lower loss value. A smooth learning rate decay curve also likely helped with this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 loss: 23.31816291809082\n",
      "Iteration 10000 loss: 2.2284233570098877\n",
      "Iteration 20000 loss: 2.2406561374664307\n",
      "Iteration 30000 loss: 2.1608595848083496\n",
      "Iteration 40000 loss: 2.304851531982422\n",
      "Iteration 50000 loss: 2.424760341644287\n",
      "Iteration 60000 loss: 2.4278080463409424\n",
      "Iteration 70000 loss: 2.20918607711792\n",
      "Iteration 80000 loss: 2.1471633911132812\n",
      "Iteration 90000 loss: 2.117159366607666\n",
      "Iteration 100000 loss: 2.3369579315185547\n",
      "Iteration 110000 loss: 2.033106803894043\n",
      "Iteration 120000 loss: 2.0824880599975586\n",
      "Iteration 130000 loss: 2.192506790161133\n",
      "Iteration 140000 loss: 2.126777410507202\n",
      "Iteration 150000 loss: 1.9903192520141602\n",
      "Iteration 160000 loss: 2.099057674407959\n",
      "Iteration 170000 loss: 2.306813955307007\n",
      "Iteration 180000 loss: 2.1502556800842285\n",
      "Iteration 190000 loss: 2.390268325805664\n",
      "Iteration 200000 loss: 2.414684772491455\n",
      "Iteration 210000 loss: 2.091949939727783\n",
      "Iteration 220000 loss: 1.9811478853225708\n",
      "Iteration 230000 loss: 2.1161515712738037\n",
      "Iteration 240000 loss: 2.1991453170776367\n",
      "Iteration 250000 loss: 2.077228546142578\n",
      "Iteration 260000 loss: 2.1640939712524414\n",
      "Iteration 270000 loss: 2.0658717155456543\n",
      "Iteration 280000 loss: 2.2298574447631836\n",
      "Iteration 290000 loss: 2.120208501815796\n"
     ]
    }
   ],
   "source": [
    "emb_size = 10\n",
    "block_size = 3\n",
    "num_chars = len(chars)\n",
    "hidden_layer_size = 200\n",
    "X, Y = build_inputs_and_labels(words, block_size)\n",
    "parameters = init_parameters(num_chars, block_size, emb_size, hidden_layer_size)\n",
    "losses = gradient_descent(X_train, Y_train, parameters, iterations=300000, minibatch_size=128, lr=0.2, lr_decay=0.00002, regularization=0.01, print_every=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x3778114c0>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(torch.tensor(losses).log10())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the train and validation losses are both improvements over our results in lecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(x, y, parameters):\n",
    "    logits = forward(x, parameters)\n",
    "    loss = torch.nn.functional.cross_entropy(logits, y)\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1127407550811768"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(X_train, Y_train, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1731631755828857"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(X_dev, Y_dev, parameters)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, when we try the data on the test set, we acheive a similar result to validation. (If we hadn't we may have accidentally overfit to the validation set via tuning hyperparameters.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1605467796325684"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(X_test, Y_test, parameters)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can generate some names with the trained model to verify the model works well:\n",
    "\n",
    "I added some features to the generate function that allows the user to specify a minimum and maximum length!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(parameters, block_size, min_chars=3, max_chars=20):\n",
    "    C, W1, b1, W2, b2 = parameters\n",
    "    context = [0] * block_size\n",
    "    out = []\n",
    "    for i in range(max_chars):\n",
    "        logits = forward(torch.tensor([context]), parameters)\n",
    "        probs = torch.nn.functional.softmax(logits, dim=1)\n",
    "        if i < min_chars:\n",
    "            probs[0, 0] = 0\n",
    "        ix = torch.multinomial(probs, 1).item()\n",
    "        if ix == 0:\n",
    "            break\n",
    "        out.append(itos[ix])\n",
    "        context = context[1:] + [ix]\n",
    "\n",
    "    return ''.join(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maemolessahborlealii\n",
      "gakantt\n",
      "kalai\n",
      "pourto\n",
      "kor\n",
      "ben\n",
      "bodiezela\n",
      "aah\n",
      "kariis\n",
      "juliondolian\n",
      "abduya\n",
      "jadie\n",
      "zasenegorowdohy\n",
      "jmy\n",
      "sajaochlonilerlin\n",
      "soleaon\n",
      "joudmese\n",
      "selianam\n",
      "kylenesin\n",
      "briello\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(generate(parameters, 3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For fun, we can try to generate some really long names:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hasleightstiva\n",
      "anisondreddiricheston\n",
      "kayabiyonnaviya\n",
      "abindieannae\n",
      "ariowalereth\n",
      "isynielantanny\n",
      "siyaannoelynn\n",
      "zetanellynne\n",
      "caanayloniah\n",
      "nahiorington\n",
      "kaydencortez\n",
      "kassaromiani\n",
      "nakalijallyssani\n",
      "priyamaramylah\n",
      "zaleelahiminah\n",
      "ruzifforelon\n",
      "skenysonstin\n",
      "muhambrieseranderance\n",
      "eversiahrocklynn\n",
      "amperithmaren\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(generate(parameters, 3, min_chars=12, max_chars=40))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E02: \n",
    "#### *I was not careful with the intialization of the network in this video. (1) What is the loss you'd get if the predicted probabilities at initialization were perfectly uniform? What loss do we achieve? (2) Can you tune the initialization to get a starting loss that is much more similar to (1)?*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the predicted probabilities were perfectly uniform, per the log-likelihood formula the loss would be -log(1/27), given a dataset with 27 characters."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can verify that this is the case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(20)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_actual = Y_train[0]\n",
    "y_actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
       "        0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
       "        0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = torch.ones(27).divide(27)\n",
    "logits"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'd also apply a softmax activation, but it results in the exact same logits if the logits are all the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
       "        0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
       "        0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.softmax(logits, dim=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it really doesn't matter what value the weights hold. However, the tanh activation is more informative when values are close to zero, so we should strive to keep the weights closer to zero (rather than say, initialize them all to 10000000)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.2958)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.cross_entropy(logits, y_actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.295836866004329"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "-math.log(1/27)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our starting loss is much higher (~23!). To acheive a similar loss, we could make every weight and bias uniform across layers throughout the network. Before, we sampled weights between 0 and 1. To acheive a starting loss of -log(1/27), we can initialize them all to the same value, 0.5 sounds appropriate given that it's in the center of our previous distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_parameters(num_chars, block_size, embedding_size, hidden_layer_size):\n",
    "    C = torch.full((num_chars, embedding_size), 0.5, requires_grad=True)\n",
    "    W1 = torch.full((embedding_size * block_size, hidden_layer_size), 0.5, requires_grad=True)\n",
    "    b1 = torch.full((hidden_layer_size,), 0.5, requires_grad=True)\n",
    "    W2 = torch.full((hidden_layer_size, num_chars), 0.5, requires_grad=True)\n",
    "    b2 = torch.full((num_chars,), 0.5, requires_grad=True)\n",
    "\n",
    "    return [C, W1, b1, W2, b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_parameters = init_parameters(num_chars, block_size, emb_size, hidden_layer_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
       "         0.5000],\n",
       "        [0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
       "         0.5000],\n",
       "        [0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
       "         0.5000]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_parameters[0][:3]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can verify that we acheive the desired starting loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.295837163925171"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(X_train, Y_train, new_parameters)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E03: \n",
    "#### *Read the Bengio et al 2003 paper (link above), implement and try any idea from the paper. Did it work?*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One idea we could try from the paper is mixing n-gram (in this case, trigram) probabilities with the neural network probabilities to get a final probability, s.t. with each probability having a weight of 0.5. In their results, the network consistently performed better with this technique. The authors suggested that this suggests that the trigram and neural network models tend to make errors in different places.\n",
    "\n",
    "To acheive this, we can first instantiate and populate a trigram matrix. It's probably prudent just to compute this on the training dataset rather than the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigrams = torch.zeros((27 * 27), 27)\n",
    "\n",
    "for word in train_words:\n",
    "    ids = ([0] * (block_size - 1)) + [stoi[c] for c in word] + [0]\n",
    "    for i in range(len(ids) - 2):\n",
    "        trigrams[(ids[i] * 27) + ids[i + 1], ids[i + 2]] += 1\n",
    "\n",
    "trigrams = (trigrams / trigrams.sum(dim=1, keepdim=True)).nan_to_num(nan=0.0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can update the evaluation function to average the network output and the trigram output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(x, y, parameters, trigrams):\n",
    "    logits = forward(x, parameters) \n",
    "    preds = (torch.softmax(logits, dim=1) * 0.5) + (torch.softmax(trigrams[x[:, 1] * 27 + x[:, 2]], dim=1) * 0.5)\n",
    "    loss = -preds[torch.arange(y.shape[0]), y].log().mean()\n",
    "    \n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.382201671600342"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(X_train, Y_train, parameters, trigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.407227039337158"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(X_dev, Y_dev, parameters, trigrams)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This technique does not improve our model's performance. Perhaps this technique tends to work better on word-level models like in the paper rather than character-level models -- perhaps because the embeddings needed to properly represent a letter are much simpler than those for a word, meaning that ensambling our neural network with the trigram model does not compensate for any of the neural network's error."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could also try introducing the trigram mixing into our training loop, but I am skeptical:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_step(x, y, parameters, trigrams, lr=0.1):\n",
    "    logits = forward(x, parameters)\n",
    "    preds = (torch.softmax(logits, dim=1) * 0.5) + (torch.softmax(trigrams[x[:, 1] * 27 + x[:, 2]], dim=1) * 0.5)\n",
    "    loss = -preds[torch.arange(y.shape[0]), y].log().mean()\n",
    "    loss.backward()\n",
    "    for p in parameters:\n",
    "        p.data -= p.grad * lr\n",
    "        p.grad = None\n",
    "    return loss.item()\n",
    "\n",
    "def gradient_descent(x, y, parameters, trigrams, iterations=100, minibatch_size=100, lr=0.1, lr_decay=0.001, regularization=0.01, print_every=10):\n",
    "    losses = []\n",
    "    for i in range(iterations):\n",
    "        batch_indices = torch.randint(0, x.shape[0], (minibatch_size,))\n",
    "        xi = x[batch_indices]\n",
    "        yi = y[batch_indices]\n",
    "        reg_term = torch.sum(torch.stack([(p**2).sum() for p in parameters])).divide(torch.sum(torch.tensor([p.numel() for p in parameters]))) * regularization\n",
    "        loss = optimize_step(xi, yi, parameters, trigrams, lr) + reg_term\n",
    "        losses.append(loss)\n",
    "        if i % print_every == 0:\n",
    "            print(f'Iteration {i} loss: {loss}')\n",
    "        lr = lr * (1 - lr_decay)\n",
    "    return losses\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 loss: 3.208648443222046\n",
      "Iteration 10000 loss: 3.071230888366699\n",
      "Iteration 20000 loss: 2.901762008666992\n",
      "Iteration 30000 loss: 2.9484827518463135\n",
      "Iteration 40000 loss: 2.709425449371338\n",
      "Iteration 50000 loss: 2.8135197162628174\n",
      "Iteration 60000 loss: 2.920710325241089\n",
      "Iteration 70000 loss: 2.854020118713379\n",
      "Iteration 80000 loss: 2.8287267684936523\n",
      "Iteration 90000 loss: 2.84387469291687\n",
      "Iteration 100000 loss: 2.765397787094116\n",
      "Iteration 110000 loss: 2.8810603618621826\n",
      "Iteration 120000 loss: 2.8022632598876953\n",
      "Iteration 130000 loss: 2.7869958877563477\n",
      "Iteration 140000 loss: 2.8552708625793457\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m new_parameters \u001b[39m=\u001b[39m init_parameters(num_chars, block_size, emb_size, hidden_layer_size)\n\u001b[0;32m----> 2\u001b[0m losses \u001b[39m=\u001b[39m gradient_descent(X_train, Y_train, new_parameters, trigrams, iterations\u001b[39m=\u001b[39;49m\u001b[39m300000\u001b[39;49m, minibatch_size\u001b[39m=\u001b[39;49m\u001b[39m128\u001b[39;49m, lr\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m, lr_decay\u001b[39m=\u001b[39;49m\u001b[39m0.00002\u001b[39;49m, regularization\u001b[39m=\u001b[39;49m\u001b[39m0.01\u001b[39;49m, print_every\u001b[39m=\u001b[39;49m\u001b[39m10000\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[43], line 18\u001b[0m, in \u001b[0;36mgradient_descent\u001b[0;34m(x, y, parameters, trigrams, iterations, minibatch_size, lr, lr_decay, regularization, print_every)\u001b[0m\n\u001b[1;32m     16\u001b[0m yi \u001b[39m=\u001b[39m y[batch_indices]\n\u001b[1;32m     17\u001b[0m reg_term \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msum(torch\u001b[39m.\u001b[39mstack([(p\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m)\u001b[39m.\u001b[39msum() \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m parameters]))\u001b[39m.\u001b[39mdivide(torch\u001b[39m.\u001b[39msum(torch\u001b[39m.\u001b[39mtensor([p\u001b[39m.\u001b[39mnumel() \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m parameters]))) \u001b[39m*\u001b[39m regularization\n\u001b[0;32m---> 18\u001b[0m loss \u001b[39m=\u001b[39m optimize_step(xi, yi, parameters, trigrams, lr) \u001b[39m+\u001b[39m reg_term\n\u001b[1;32m     19\u001b[0m losses\u001b[39m.\u001b[39mappend(loss)\n\u001b[1;32m     20\u001b[0m \u001b[39mif\u001b[39;00m i \u001b[39m%\u001b[39m print_every \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "Cell \u001b[0;32mIn[43], line 2\u001b[0m, in \u001b[0;36moptimize_step\u001b[0;34m(x, y, parameters, trigrams, lr)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize_step\u001b[39m(x, y, parameters, trigrams, lr\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     logits \u001b[39m=\u001b[39m forward(x, parameters)\n\u001b[1;32m      3\u001b[0m     preds \u001b[39m=\u001b[39m (torch\u001b[39m.\u001b[39msoftmax(logits, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m*\u001b[39m \u001b[39m0.5\u001b[39m) \u001b[39m+\u001b[39m (torch\u001b[39m.\u001b[39msoftmax(trigrams[x[:, \u001b[39m1\u001b[39m] \u001b[39m*\u001b[39m \u001b[39m27\u001b[39m \u001b[39m+\u001b[39m x[:, \u001b[39m2\u001b[39m]], dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m*\u001b[39m \u001b[39m0.5\u001b[39m)\n\u001b[1;32m      4\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39m-\u001b[39mpreds[torch\u001b[39m.\u001b[39marange(y\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]), y]\u001b[39m.\u001b[39mlog()\u001b[39m.\u001b[39mmean()\n",
      "Cell \u001b[0;32mIn[8], line 5\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(x, parameters)\u001b[0m\n\u001b[1;32m      3\u001b[0m emb \u001b[39m=\u001b[39m C[x]\n\u001b[1;32m      4\u001b[0m h \u001b[39m=\u001b[39m (emb\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, emb\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m*\u001b[39m emb\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m]) \u001b[39m@\u001b[39m W1) \u001b[39m+\u001b[39m b1\n\u001b[0;32m----> 5\u001b[0m h \u001b[39m=\u001b[39m h\u001b[39m.\u001b[39;49mtanh()\n\u001b[1;32m      6\u001b[0m h \u001b[39m=\u001b[39m (h \u001b[39m@\u001b[39m W2) \u001b[39m+\u001b[39m b2\n\u001b[1;32m      7\u001b[0m \u001b[39mreturn\u001b[39;00m h\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "new_parameters = init_parameters(num_chars, block_size, emb_size, hidden_layer_size)\n",
    "losses = gradient_descent(X_train, Y_train, new_parameters, trigrams, iterations=300000, minibatch_size=128, lr=0.2, lr_decay=0.00002, regularization=0.01, print_every=10000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After many iterations with no signs of life, I decided to stop training early."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
